{
    "input": {
        "project_id": 30
    },
    "train_val_split": {
        "method": "random",
        "split": "train",
        "percent": 80
    },
    "classes": [
        "cat",
        "dog",
        "horse",
        "sheep",
        "squirrel"
    ],
    "model": {
        "source": "Pretrained models",
        "model_name": "yolov12n"
    },
    "hyperparameters": "# Learn more about YOLO hyperparameters: https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml\n\n# Train settings\nepochs: 30 # (int) number of epochs to train for\ntime: # (float, optional) number of hours to train for, overrides epochs if supplied\npatience: 100 # (int) epochs to wait for no observable improvement for early stopping of training\nbatch: -1 # (int) number of images per batch (-1 for AutoBatch)\nimgsz: 640 # (int | list) input images size as int for train and val modes, or list[h,w] for predict and export modes\nsave: True # (bool) save train checkpoints and predict results\nsave_period: 5 # (int) Save checkpoint every x epochs (disabled if < 1)\nworkers: 8 # (int) number of worker threads for data loading (per RANK if DDP)\noptimizer: auto # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\nverbose: False # (bool) whether to print verbose output\nseed: 0 # (int) random seed for reproducibility\ncos_lr: False # (bool) use cosine learning rate scheduler\nclose_mosaic: 10 # (int) disable mosaic augmentation for final epochs (0 to disable)\namp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check\nfreeze: None # (int | list, optional) freeze first n layers, or freeze list of layer indices during training\n\n# Hyperparameters\nlr0: 0.01 # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\nlrf: 0.01 # (float) final learning rate (lr0 * lrf)\nmomentum: 0.937 # (float) SGD momentum/Adam beta1\nweight_decay: 0.0005 # (float) optimizer weight decay 5e-4\nwarmup_epochs: 3.0 # (float) warmup epochs (fractions ok)\nwarmup_momentum: 0.8 # (float) warmup initial momentum\nwarmup_bias_lr: 0.1 # (float) warmup initial bias lr\nbox: 7.5 # (float) box loss gain\ncls: 0.5 # (float) cls loss gain (scale with pixels)\ndfl: 1.5 # (float) dfl loss gain\npose: 12.0 # (float) pose loss gain\nkobj: 1.0 # (float) keypoint obj loss gain\nnbs: 64 # (int) nominal batch size\nhsv_h: 0.015 # (float) image HSV-Hue augmentation (fraction)\nhsv_s: 0.7 # (float) image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4 # (float) image HSV-Value augmentation (fraction)\ndegrees: 0.0 # (float) image rotation (+/- deg)\ntranslate: 0.1 # (float) image translation (+/- fraction)\nscale: 0.5 # (float) image scale (+/- gain)\nshear: 0.0 # (float) image shear (+/- deg)\nperspective: 0.0 # (float) image perspective (+/- fraction), range 0-0.001\nflipud: 0.0 # (float) image flip up-down (probability)\nfliplr: 0.5 # (float) image flip left-right (probability)\nbgr: 0.0 # (float) image channel BGR (probability)\nmosaic: 1.0 # (float) image mosaic (probability)\nmixup: 0.0 # (float) image mixup (probability)\ncopy_paste: 0.0 # (float) segment copy-paste (probability)\ncopy_paste_mode: \"flip\" # (str) the method to do copy_paste augmentation (flip, mixup)\n",
    "options": {
        "model_benchmark": {
            "enable": false,
            "speed_test": false
        },
        "export": {
            "ONNXRuntime": false,
            "TensorRT": false
        },
        "cache_project": true
    }
}